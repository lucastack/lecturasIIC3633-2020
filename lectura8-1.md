# Lectura: A user-centric evaluation framework for recommender systems. (Pu, P., Chen, L. and Hu, R. (2011).

El paper menciona que existe abundante investigación en cómo evaluar un sistema recomendador, tema que también hemos visto a lo largo del curso. Típicamente se propone alguna métrica y se evalúa numéricamente las recomendaciones hechas a los usuarios con ella. En el presente paper, los investigadores proponen una manera diferente de evaluación: en lugar de centrar nuestra atención en la lista de recomendación *per se*, proponen evaluar características cualitativas de la experiencia que tiene el usuario con el sistema recomendador. Esta idea es bastante razonable dado que finalmente el objetivo es que el usuario encuentre alguna ganancia de las recomendaciones que se hacen y es su percepción de esta ganancia lo que importa, es decir, el sistema recomendador debe lograr "captar" al usuario más que conseguir buenos números en alguna métrica, objetivos que no siempre se encuentran correlacionados.

El framework propuesto de evaluación es ResQue (Recommender systems’ Quality of user experience), el cual es técnicamente un cuestionario dirigido a los usuarios el cual permite obtener un feedback de los puntos más relevantes (según los investigadores) sobre su experiencia con el sistema recomendador. Las preguntas de ResQue están divididas en 4 tópicos principales: cualidades percibidas por el usuario, las creencias del usuario a partir de estas cualidades, las actitudes (o sentimientos) del usuario, y por último, las intenciones de su comportamiento. 

Dentro de las cualidades percibidas por el usuario se encuentra el *accuracy* percibido, el cual consiste en que el sistema recomendador haya captado correctamente los intereses del usuario. Los investigadores mencionan que existe una fuerte correlación entre esta característica subjetiv y el *accuracy* típico visto como métrica, es decir, si los usuarios consideran que el sistema recomendador captura sus intereses es muy probable que el algoritmo por debajo tenga buenos resultados en términos de *accuracy*. Este resultado es muy importante pues da luces de que si bien las métricas no necesariamente otorgan buena experiencia para los usuarios, si parecen estar relacionadas de alguna manera con la última.

En este mismo tópico se toca el tema de la familiaridad y la novedad de las recomendaciones. Típicamente, si a un usuario le gustó un cierto item I es razonable pensar que también le gustarán los items similares a I, esto hace relación con la familiaridad del usuario con el sistema recomendador. Sin embargo, supongamos que este usuario visita una página de e-commerce y está interesado en comprar una bicicleta. Naturalmente cuando el usuario ingresa su búsqueda la página puede comenzar a recomendar otras bicicletas, lo cual muestra también muy poca diversidad. Como mencionan los investigadores, esto puede ser frustrante para el usuario porque prácticamente es demasiado similar la recomendación y no permite que el usuario vea nuevos items que pueden ser de valor para él, por ejemplo, otros items ligados al deporte o al ciclismo en lugar de sólo bicicletas.

Un resultado que llama la atención por lo realista que es personalmente, es que a los usuarios les gusta cuando las recomendación son explicadas, osea, cuando la página dice "sugerido porque viste X objeto". Desde el punto de vista del usuario esto aumenta la confianza en el sistema recomendador porque de alguna manera se siente individualizado y no como un usuario genérico al que se le hacen las recomendaciones. Hace que el usuario sienta que las recomendaciones funcionan y que la página está "bien hecha", lo que aumenta su confianza.

Una utilidad práctica que posee ResQue, es que no solamente indaga en la percepción de las recomendaciones, si no que también en los aspectos de visualización de ellas, lo que permite que los diseñadores de la plataforma tengan un feedback acerca de cómo organizar de mejor manera la información proveniente de los algoritmos de recomendación.

En general, corresponde a un paper muy claro en términos de escritura y organización. Me parece muy interesante la propuesta ya que prácticamente está mezclando psicología con sistemas recomendadores, aunque por esto mismo me da la impresión de que hizo falta ahondar más en la dimensión psicológica de los usuarios más que en los hechos. Algo que hubiese aportado muchísimo a la discusión es agregar resultados de este cuestionario y comparar el rendimiento numérico del algoritmo recomendador utilizado, quizás de esta manera se llegue a conclusiones más balanceadas y completas entre características cualitativas y cuantitativas acerca del rendimiento de un sistema. 


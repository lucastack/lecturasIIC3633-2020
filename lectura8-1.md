# Lectura: A user-centric evaluation framework for recommender systems. (Pu, P., Chen, L. and Hu, R. (2011).

El paper menciona que existe abundante investigación en cómo evaluar un sistema recomendador, tema que también hemos visto a lo largo del curso. Típicamente se propone alguna métrica y se evalúa numéricamente las recomendaciones hechas a los usuarios con ella. En el presente paper, los investigadores proponen una manera diferente de evaluación: en lugar de centrar nuestra atención en la lista de recomendación *per se*, proponen evaluar características cualitativas de la experiencia que tiene el usuario con el sistema recomendador. Esta idea es bastante razonable dado que finalmente el objetivo es que el usuario encuentre alguna ganancia de las recomendaciones que se hacen y es su percepción de esta ganancia lo que importa, es decir, el sistema recomendador debe lograr "captar" al usuario más que conseguir buenos números en alguna métrica, objetivos que no siempre se encuentran correlacionados.

El framework propuesto de evaluación es ResQue (Recommender systems’ Quality of user experience), el cual es técnicamente un cuestionario dirigido a los usuarios el cual permite obtener un feedback de los puntos más relevantes (según los investigadores) sobre su experiencia con el sistema recomendador. Las preguntas de ResQue están divididas en 4 tópicos principales: cualidades percibidas por el usuario, las creencias del usuario a partir de estas cualidades, las actitudes (o sentimientos) del usuario, y por último, las intenciones de su comportamiento. 

Dentro de las cualidades percibidas por el usuario se encuentra el *accuracy* percibido, el cual consiste en que el sistema recomendador haya captado correctamente los intereses del usuario. Los investigadores mencionan que existe una fuerte correlación entre esta característica subjetiv y el *accuracy* típico visto como métrica, es decir, si los usuarios consideran que el sistema recomendador captura sus intereses es muy probable que el algoritmo por debajo tenga buenos resultados en términos de *accuracy*. Este resultado es muy importante pues da luces de que si bien las métricas no necesariamente otorgan buena experiencia para los usuarios, si parecen estar relacionadas de alguna manera con la última.

En este mismo tópico se toca el tema de la familiaridad y la novedad de las recomendaciones. Típicamente, si a un usuario le gustó un cierto item I es razonable pensar que también le gustarán los items similares a I, esto hace relación con la familiaridad del usuario con el sistema recomendador. Sin embargo, supongamos que este usuario visita una página de e-commerce y está interesado en comprar una bicicleta. Naturalmente cuando el usuario ingresa su búsqueda la página puede comenzar a recomendar otras bicicletas, lo cual muestra también muy poca diversidad. Como mencionan los investigadores, esto puede ser frustrante para el usuario porque prácticamente es demasiado similar la recomendación y no permite que el usuario vea nuevos items que pueden ser de valor para él, por ejemplo, otros items ligados al deporte o al ciclismo en lugar de sólo bicicletas.

Un resultado que llama la atención por lo real que se siente, es que a los usuarios les gusta cuando las recomendación son explicadas, osea, cuando la página dice "sugerido porque viste X objeto". Desde el punto de vista del usuario esto aumenta la confianza en el sistema recomendador porque de alguna manera se siente individualizado, y no como un usuario genérico al que le llegan las recomendaciones. Hace que el usuario sienta que las recomendaciones funcionan y que la página está "bien hecha".     

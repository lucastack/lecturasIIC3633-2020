# Lectura: Item-based collaborative filtering recommendation algorithms. Sarwar, B., Karypis, G., Konstan, J., & Riedl, J. (2001).

## Resumen

El paper comienza introduciendo el tema de los sistemas recomendadores y el desafío que presentan en cuanto a escalabilidad. Luego, se explican dos enfoques distintos: algoritmos *user-based* y algoritmos *item-based* para filtrado colaborativo. La tesis a demostrar es que el enfoque basado en items resuelve el problema de la escalabilidad, es decir, que entrega buenos resultados en términos de precisión y uso de recursos para una gran cantidad de datos. Finalmente se realizan experimentos computacionales con un conjunto de datos extraido de MovieLens, con lo cual los investigadores concluyen la validación de su tesis.   

## Comentarios

Cuando se introduce el problema de escalabilidad se dice que los problemas se producen cuando tenemos una gran cantidad de datos: millones de usuarios o items, sin embargo, el conjunto de datos que se trabaja no coincide con esta descripción. Me parece que es necesario escoger una base de datos más grande y comparar los dos tipos de enfoque (*item-based*  vs *user-based*), cosa que no fue lo que se hizo. Con respecto a esta comparación, a pesar de que existen citas de literatura, creo que faltó adjuntar una tabla que muestre la cantidad de recomendaciones por segundo y del tiempo total utilizado (análogo a la Fig. 8) del enfoque basado en usuario, esto con el fin de despejar cualquier duda de que efectivamente el enfoque basado en items es el que resuelve el problema de la escalabilidad. 

Otra cosa que me parece que no se le da el cuidado suficiente es el significado de la métrica de error, el llamado *Mean Square Error*. Los autores señalan que escogen esa métrica porque es de las más usuales y, basados en su experiencia, se obtienen resultados similares a algunas otras, sin embargo, en ningún momento se da una interpretación de esa cantidad. Es en ese punto donde me surgen dudas, por ejemplo, ¿qué significa que el MSE sea 0.755? ¿existe mucha diferencia con que sea 0.820?. De la definición se entiende que funciona como una métrica de error: entre mejores resultados menor valor de MSE, pero queda muy en el aire su significado. 

Considero que está muy bien que hayan seleccionado distintas proporciones de *training set* y *testing set*, así podemos darnos una idea de que tantos datos necesitamos para entrenar (o precomputar) un modelo de filtrado colaborativo basado en items. En general, los resultados mostraron que una proporción del 80% nos brinda los mejores resultados. Otra cosa que creo que estuvo muy bien fue haber discutido y justificado qué medida de similaridad ocuparían entre los items, sin esta medida la elección parecería arbitraria.

El resultado que más me impresionó fue el relativo al tamaño de los modelos: que con una pequeña fracción de los items es posible hacer predicciones muy buenas (con respecto a tomar todos los items), es decir, este proceso es fácilmente escalable con respecto al tamaño de los items. En general me parece un muy buen paper introductorio al tema: presenta las problemáticas del área, explica las distintas componentes de los algoritmos a revisar y muestra claramente los resultados.

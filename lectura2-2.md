# Lectura: BPR: Bayesian personalized ranking from implicit feedback. Rendle, S., Freudenthaler, C., Gantner, Z., & Schmidt-Thieme, L. (2009).

## Resumen
Este paper presenta un nuevo enfoque para generar modelos de sistemas recomendadores con feedback implícito. Provee de un modelo de optimización (una función a optimizar) que denominan BPR-Opt, el cual es básicamente maximizar el valor de un operador relacionado con la probabilidad a posteriori, además de un método de aprendizaje para hallar tal óptimo: LearnBPR, que consiste en usar algoritmo de gradiente estocástico con bootstraping sin reemplazo. Se utiliza este enfoque con los modelos kNN y factorización matricial y se encuentran resultados muy superiores a las estrategias de aprendizaje "tradicionales" (o no bayesianos).

## Comentarios

El origen de este enfoque es considerar que lo que se busca es **ordenar** los items de acuerdo a su preferencia para un cierto usuario. Por este motivo, a diferencia de los otros modelos que hemos visto, se trabaja con pares de items (i,j) e intenamos generar un orden < para cada usuario u, tal que i > j significa que i tiene mayor preferencia que j para el usuario en cuestión. Entonces, lo que buscamos en BPR es maximizar la probabilidad de que los items estén en su orden correcto. Me parece muy elegante esta nueva formulación, como también fascinante el hecho de que mirar un problema desde otra perspectiva podamos encontrar nuevas (y mejores) soluciones. 

Como considerar los datos de la forma (u, i, j) en el set de entrenamiento incrementa el tamaño de los datos cuadráticamente, es fundamental que se haya utilizado gradiente estocástico para garantizar que el algoritmo sea más escalable. Además, los investigadores no sólo argumentan esto, si no que agregan un gráfico donde compara esta elección versus utilizar el descenso de gradiente "full", mostrando la clara superioridad del primero. Una cosa que podría discutirse en este punto es la manera en que se realizan las muestras: se propone ir tomando dato a dato (tal como en gradiente estocástico usual) y moverse en esa dirección de gradiente, sin embargo, ¿que tal si tomamos más datos, no todos, sacrificando un poco de tiempo pero obteniéndose menor error? es decir, escogiendo un punto intermedio entre full gradiente y gradiente estocástico, ¿Cómo escalaría esta alternativa?.    

En la sección de resultados se comparan distintos modelos con la optimización propuesta y sin ella, mostrándose una clara mejoría al utilizarla. Además, los investigadores realizan los experimentos en dos conjuntos de datos distintos a fin de proveer de mayor generalidad, lo cual es muy importante dado que **no** se trata de un modelo como tal y la idea es que pueda acoplarse con los distintos modelos ya existentes (kNN y MF, en este caso). Con respecto a esto, me pareció increíble que con *Matrix Factorization* se obtengan resultados muy buenos con pocos factores latentes, lo que se relaciona con el otro paper de esta semana, mostrando también una clara superioridad de BPR.

Para finalizar, el paper básicamente provee de una gran herramienta matemática y computacional. Me costó bastante seguir todo el hilo argumental de la derivación matemática del modelo, creo que se me hizo necesario leer con más detalle este punto (como en un libro: paso a paso), sin embargo, me parece razonable dejar las cosas definidas y explicar en un alto nivel a fin de entregar la información y los resultados de manera concisa. En cuanto a esto último, pareciera ser que BPR es lo mejor hasta la fecha para feedback implícito, o al menos, esa impresión me dió ¿Es esto realmente así, o existen otros enfoques mejores? ¿Se mantienen los resultados para **cualquier** set de datos? 

